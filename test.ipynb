{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from definitions import *\n",
      "import pickle\n",
      "import montecarlo_experiments as mce\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/dist-packages/sklearn/pls.py:7: DeprecationWarning: This module has been moved to cross_decomposition and will be removed in 0.16\n",
        "  \"removed in 0.16\", DeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "############### Creating the objects within different clusters\n",
      "\n",
      "n_objects=32\n",
      "n_clusters=4\n",
      "dimension=2\n",
      "scale=3\n",
      "\n",
      "[set_of_objects,real_clusters,fig_ob]=pbg.generate_objects(n_objects,n_clusters,dimension,scale)\n",
      "# plt.savefig('Results/objects.png')\n",
      "\n",
      "############### Creating assessors and generating votes with adaptive method\n",
      "\n",
      "n_assessors=6\n",
      "var_min=0.5\n",
      "var_max=0.5\n",
      "beta_param=5\n",
      "set_of_assessors=pbg.generate_assessors(n_assessors,var_min,var_max,beta_param)\n",
      "\n",
      "################  Creating adaptive method\n",
      "adaptive_method=ass.Adaptive_method(nm.rand_ass_gene,nm.rand_ob_gene)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeIAAAEACAYAAABvZXUqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fa4ed700710>"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=0\n",
      "for ob in set_of_objects:\n",
      "    print i, ob.features\n",
      "    i+=1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 [-1.1655483  -0.66483597]\n",
        "1 [-0.24428358 -2.01678355]\n",
        "2 [-1.67271459 -0.500742  ]\n",
        "3 [ 1.28219608 -1.61153657]\n",
        "4 [-1.23858021 -0.79766837]\n",
        "5 [ 0.05409685  1.05887964]\n",
        "6 [-0.67030503 -0.15903114]\n",
        "7 [ 3.0370679   0.25408164]\n",
        "8 [-0.59815593  0.73701622]\n",
        "9 [-0.71330268 -1.40026065]\n",
        "10 [ 0.46655936 -0.16499672]\n",
        "11 [ 2.26361713  3.72623567]\n",
        "12 [ 0.389937    2.28484528]\n",
        "13 [ 4.41089457  2.37327456]\n",
        "14 [ 2.69327401  0.21337652]\n",
        "15 [ 1.76469573  2.71317417]\n",
        "16 [ 2.01043173  4.61671184]\n",
        "17 [ 2.99606353  0.27773291]\n",
        "18 [ 4.051732    3.04251714]\n",
        "19 [ 2.87803534  2.71140295]\n",
        "20 [ 4.83700367  3.11089254]\n",
        "21 [ 2.59234006  0.47573269]\n",
        "22 [ 11.64893701   6.14861765]\n",
        "23 [ 10.41976072   6.58575887]\n",
        "24 [ 8.77673265  4.40052119]\n",
        "25 [ 11.45368362   4.24695207]\n",
        "26 [ 11.43267988   2.84144483]\n",
        "27 [ 10.74255803   3.77866028]\n",
        "28 [ 11.31091154   4.66269387]\n",
        "29 [ 11.41664056   4.46991769]\n",
        "30 [ 10.57242455   4.0376233 ]\n",
        "31 [ 8.92575747  3.04730351]\n",
        "32 [ 8.54392751  5.11945634]\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exp=ass.Experiment(set_of_assessors,set_of_objects,adaptive_method)\n",
      "n_assessments=50\n",
      "n_object_per_assessment=6\n",
      "True_K=False\n",
      "Known_K=False\n",
      "for i in range(n_assessments):\n",
      "    exp.procede_adaptive_assessment(n_clusters,True_K,Known_K,n_object_per_assessment,0,0)\n",
      "Votes=exp.get_results()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results=Votes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "{(1, 3): True,\n",
        " (1, 10): False,\n",
        " (1, 11): False,\n",
        " (1, 12): False,\n",
        " (1, 17): True,\n",
        " (1, 18): True,\n",
        " (1, 19): True,\n",
        " (1, 27): False,\n",
        " (1, 28): False,\n",
        " (2, 6): True,\n",
        " (2, 7): True,\n",
        " (2, 16): False,\n",
        " (2, 30): False,\n",
        " (3, 1): True,\n",
        " (3, 10): False,\n",
        " (3, 11): False,\n",
        " (3, 12): False,\n",
        " (3, 14): False,\n",
        " (3, 17): True,\n",
        " (3, 18): True,\n",
        " (3, 19): False,\n",
        " (3, 21): False,\n",
        " (3, 24): False,\n",
        " (3, 27): False,\n",
        " (3, 28): False,\n",
        " (3, 31): False,\n",
        " (4, 7): True,\n",
        " (4, 11): True,\n",
        " (4, 13): False,\n",
        " (4, 15): False,\n",
        " (4, 18): True,\n",
        " (4, 23): True,\n",
        " (4, 25): False,\n",
        " (4, 28): False,\n",
        " (4, 29): False,\n",
        " (5, 6): True,\n",
        " (5, 7): True,\n",
        " (5, 18): True,\n",
        " (5, 28): False,\n",
        " (5, 31): False,\n",
        " (6, 2): True,\n",
        " (6, 5): True,\n",
        " (6, 6): True,\n",
        " (6, 7): True,\n",
        " (6, 16): False,\n",
        " (6, 18): True,\n",
        " (6, 28): False,\n",
        " (6, 30): False,\n",
        " (6, 31): False,\n",
        " (7, 2): True,\n",
        " (7, 4): True,\n",
        " (7, 5): True,\n",
        " (7, 6): True,\n",
        " (7, 11): True,\n",
        " (7, 12): True,\n",
        " (7, 13): False,\n",
        " (7, 15): False,\n",
        " (7, 16): False,\n",
        " (7, 18): True,\n",
        " (7, 23): True,\n",
        " (7, 25): False,\n",
        " (7, 28): False,\n",
        " (7, 29): False,\n",
        " (7, 30): False,\n",
        " (7, 31): False,\n",
        " (10, 1): False,\n",
        " (10, 3): False,\n",
        " (10, 11): True,\n",
        " (10, 27): False,\n",
        " (10, 28): False,\n",
        " (11, 1): False,\n",
        " (11, 3): False,\n",
        " (11, 4): True,\n",
        " (11, 7): True,\n",
        " (11, 10): True,\n",
        " (11, 12): True,\n",
        " (11, 23): True,\n",
        " (11, 25): False,\n",
        " (11, 27): False,\n",
        " (11, 28): False,\n",
        " (11, 29): False,\n",
        " (12, 1): False,\n",
        " (12, 3): False,\n",
        " (12, 7): True,\n",
        " (12, 11): True,\n",
        " (12, 12): True,\n",
        " (12, 13): False,\n",
        " (12, 15): False,\n",
        " (12, 16): False,\n",
        " (12, 17): False,\n",
        " (12, 18): False,\n",
        " (12, 19): False,\n",
        " (12, 23): True,\n",
        " (12, 28): False,\n",
        " (12, 29): False,\n",
        " (13, 4): False,\n",
        " (13, 7): False,\n",
        " (13, 12): False,\n",
        " (13, 15): True,\n",
        " (13, 16): False,\n",
        " (13, 18): False,\n",
        " (13, 19): False,\n",
        " (13, 25): False,\n",
        " (14, 3): False,\n",
        " (14, 19): False,\n",
        " (14, 21): False,\n",
        " (14, 24): False,\n",
        " (14, 31): False,\n",
        " (15, 4): False,\n",
        " (15, 7): False,\n",
        " (15, 12): False,\n",
        " (15, 13): True,\n",
        " (15, 16): False,\n",
        " (15, 18): False,\n",
        " (15, 19): False,\n",
        " (15, 25): False,\n",
        " (16, 2): False,\n",
        " (16, 6): False,\n",
        " (16, 7): False,\n",
        " (16, 12): False,\n",
        " (16, 13): False,\n",
        " (16, 15): False,\n",
        " (16, 19): True,\n",
        " (16, 30): False,\n",
        " (17, 1): True,\n",
        " (17, 3): True,\n",
        " (17, 12): False,\n",
        " (17, 18): True,\n",
        " (17, 19): True,\n",
        " (18, 1): True,\n",
        " (18, 3): True,\n",
        " (18, 4): True,\n",
        " (18, 5): True,\n",
        " (18, 6): True,\n",
        " (18, 7): True,\n",
        " (18, 12): False,\n",
        " (18, 13): False,\n",
        " (18, 15): False,\n",
        " (18, 17): True,\n",
        " (18, 19): True,\n",
        " (18, 25): False,\n",
        " (18, 28): False,\n",
        " (18, 31): False,\n",
        " (19, 1): True,\n",
        " (19, 3): False,\n",
        " (19, 12): False,\n",
        " (19, 13): False,\n",
        " (19, 14): False,\n",
        " (19, 15): False,\n",
        " (19, 16): True,\n",
        " (19, 17): True,\n",
        " (19, 18): True,\n",
        " (19, 21): True,\n",
        " (19, 24): False,\n",
        " (19, 31): False,\n",
        " (21, 3): False,\n",
        " (21, 14): False,\n",
        " (21, 19): True,\n",
        " (21, 24): False,\n",
        " (21, 31): False,\n",
        " (23, 4): True,\n",
        " (23, 7): True,\n",
        " (23, 11): True,\n",
        " (23, 12): True,\n",
        " (23, 25): False,\n",
        " (23, 28): False,\n",
        " (23, 29): False,\n",
        " (24, 3): False,\n",
        " (24, 14): False,\n",
        " (24, 19): False,\n",
        " (24, 21): False,\n",
        " (24, 31): True,\n",
        " (25, 4): False,\n",
        " (25, 7): False,\n",
        " (25, 11): False,\n",
        " (25, 13): False,\n",
        " (25, 15): False,\n",
        " (25, 18): False,\n",
        " (25, 23): False,\n",
        " (25, 28): True,\n",
        " (25, 29): True,\n",
        " (27, 1): False,\n",
        " (27, 3): False,\n",
        " (27, 10): False,\n",
        " (27, 11): False,\n",
        " (27, 28): True,\n",
        " (28, 1): False,\n",
        " (28, 3): False,\n",
        " (28, 4): False,\n",
        " (28, 5): False,\n",
        " (28, 6): False,\n",
        " (28, 7): False,\n",
        " (28, 10): False,\n",
        " (28, 11): False,\n",
        " (28, 12): False,\n",
        " (28, 18): False,\n",
        " (28, 23): False,\n",
        " (28, 25): True,\n",
        " (28, 27): True,\n",
        " (28, 29): True,\n",
        " (28, 31): True,\n",
        " (29, 4): False,\n",
        " (29, 7): False,\n",
        " (29, 11): False,\n",
        " (29, 12): False,\n",
        " (29, 23): False,\n",
        " (29, 25): True,\n",
        " (29, 28): True,\n",
        " (30, 2): False,\n",
        " (30, 6): False,\n",
        " (30, 7): False,\n",
        " (30, 16): False,\n",
        " (31, 3): False,\n",
        " (31, 5): False,\n",
        " (31, 6): False,\n",
        " (31, 7): False,\n",
        " (31, 14): False,\n",
        " (31, 18): False,\n",
        " (31, 19): False,\n",
        " (31, 21): False,\n",
        " (31, 24): True,\n",
        " (31, 28): True}"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print sum([len(results[i].keys()) for i in results.keys()])/50.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "24.1\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pairs={}\n",
      "for assess in Votes:\n",
      "    for pair in Votes[assess]:\n",
      "        if pair not in pairs:\n",
      "            pairs[pair]=[0,0]\n",
      "        pairs[pair][0]+=1\n",
      "        if Votes[assess][pair]:\n",
      "           pairs[pair][1]+=1 "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "adja={}\n",
      "t=0.5\n",
      "for pair in pairs:\n",
      "    if pair[0] not in adja:\n",
      "        adja[pair[0]]=list()\n",
      "    if pairs[pair][1]/float(pairs[pair][0])>t and pair[0]!=pair[1]:\n",
      "        adja[pair[0]].append(pair[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Delta_est=em.naive_distance(Votes,n_objects)\n",
      "S_est=0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "est_adj,v=adjacency_KClusters(Delta_est,n_clusters)\n",
      "print est_adj"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1.  1.  1. ...,  1.  1.  1.]\n",
        " [ 1.  1.  1. ...,  1.  1.  1.]\n",
        " [ 1.  1.  1. ...,  1.  1.  1.]\n",
        " ..., \n",
        " [ 1.  1.  1. ...,  1.  1.  1.]\n",
        " [ 1.  1.  1. ...,  1.  1.  1.]\n",
        " [ 1.  1.  1. ...,  1.  1.  1.]]\n"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w=v[:,1:kmax]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kmax=5\n",
      "gmm_labels=GMM_cluster(w,kmax)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gmm_labels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 131,
       "text": [
        "array([3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1,\n",
        "       1, 2, 2, 2, 2, 2, 2, 2, 2])"
       ]
      }
     ],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(1,10):\n",
      "    gmm=mixture.GMM(n_components=i+1)\n",
      "    gmm.fit(v)\n",
      "    print i+1,gmm.bic(v),gmm.predict(v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2 -199.753471968 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
        "3 -278.788080449 [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1]\n",
        "4 -304.661255065 [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3]\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -280.401103745 [3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
        "6 -256.140952426 [2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 2 4 4 4 0 4 4 0 0 5 5 5 5 5 5 5 5]\n",
        "7 -231.880801106 [3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 3 1 1 1 4 1 1 1 1 6 6 6 6 6 6 6 6]\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -207.620649786 [1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 1 5 5 5 5 5 5 5 5 4 4 4 4 4 4 4 4]\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -183.360498467 [3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 3 1 4 4 1 1 1 1 1 0 0 0 6 0 0 6 0]\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -159.100347147 [1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 1 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5]\n"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gmm.bic(v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 76,
       "text": [
        "-122.91294137785346"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k=4\n",
      "km=cluster.KMeans(n_clusters=k)\n",
      "km.fit(v[:,:k-1])\n",
      "print km.labels_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 1 0 0 0 0 0 0 0 0 3 3 3 3 3 3 3 3]\n"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Kmeans_cluster(k,v):\n",
      "    km=cluster.KMeans(n_clusters=k)\n",
      "    km.fit(v[:,:k-1])\n",
      "    return km.labels_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GMM_cluster(v,kmax):\n",
      "    kbest=0\n",
      "    best_bic=9999999\n",
      "    best_predict=0\n",
      "    for i in range(1,kmax):\n",
      "        gmm=mixture.GMM(n_components=i+1)\n",
      "        gmm.fit(v)\n",
      "        bic=gmm.bic(v)\n",
      "        if bic<best_bic:\n",
      "            kbest=i+1\n",
      "            best_bic=bic\n",
      "            best_predict=gmm.predict(v)\n",
      "    return best_predict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import *\n",
      "def adjacency_KClusters(Dist,k): # To be fixed !!!\n",
      "    S=spc.similarity(Dist)\n",
      "    n=np.shape(S)[0]\n",
      "    L=spc.laplacian(S)\n",
      "    w,v=np.linalg.eig(L)\n",
      "    ind_sorted_eigvals=np.argsort(w)\n",
      "    v=v[:,ind_sorted_eigvals]\n",
      "    w=w[ind_sorted_eigvals]\n",
      "    #v=v[:,1:k]\n",
      "    clusters=Kmeans_cluster(k,v)\n",
      "    A=np.zeros((n,n))\n",
      "    for i in range(n):\n",
      "        for j in range(n):\n",
      "            if clusters[i]==clusters[j]:\n",
      "                A[i,j]=1\n",
      "    return A,v"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def centroid_ob_gene(results,n_ass,n_objects,n_object_per_assessment,Delta_est,S_est,n_cluster):\n",
      "    \n",
      "    S=spc.similarity(Delta_est)\n",
      "    n=np.shape(S)[0]\n",
      "    L=spc.laplacian(S)\n",
      "    w,v=np.linalg.eig(L)\n",
      "    ind_sorted_eigvals=np.argsort(w)\n",
      "    v=v[:,ind_sorted_eigvals]\n",
      "    w=w[ind_sorted_eigvals]\n",
      "    v=v[:,1:n_cluster]\n",
      "    \n",
      "    print v\n",
      "    \n",
      "    km=cluster.KMeans(n_clusters=n_cluster)\n",
      "    km.fit(v[:,:n_cluster-1])\n",
      "    centers=km.cluster_centers_\n",
      "    \n",
      "    # Enter the closest points to the centroid\n",
      "    choice=[]\n",
      "    for center in centers:\n",
      "        dmin=100\n",
      "        bestind=-1\n",
      "        for i in range(np.shape(v)[0]):\n",
      "            d=np.sum(np.square(center-v[i,:]))\n",
      "            #print center,v[i,:],d\n",
      "            if d<dmin:\n",
      "                bestind=i\n",
      "                dmin=d\n",
      "        choice.append(bestind)\n",
      "        \n",
      "    # Complete choice until full\n",
      "    while len(choice)<n_object_per_assessment:\n",
      "        r=np.random.randint(n_objects)\n",
      "        if r not in choice:\n",
      "            choice.append(r)\n",
      "    \n",
      "    return choice       "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 328
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_cluster=3\n",
      "n_ass=6\n",
      "choice=centroid_ob_gene(results,n_ass,n_objects,n_object_per_assessment,Delta_est,S_est,n_cluster)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.         -0.        ]\n",
        " [ 0.         -0.        ]\n",
        " [ 0.         -0.        ]\n",
        " [ 0.         -0.        ]\n",
        " [ 0.         -0.        ]\n",
        " [ 0.         -0.        ]\n",
        " [ 0.28867513  0.28409447]\n",
        " [ 0.28867513  0.30070733]\n",
        " [ 0.28867513  0.2832736 ]\n",
        " [ 0.28867513  0.29632323]\n",
        " [ 0.28867513  0.29245385]\n",
        " [ 0.28867513  0.21186116]\n",
        " [ 0.28867513 -0.34874605]\n",
        " [ 0.28867513 -0.3438474 ]\n",
        " [ 0.28867513 -0.29837516]\n",
        " [ 0.28867513 -0.33103945]\n",
        " [ 0.28867513 -0.29950264]\n",
        " [ 0.28867513 -0.04720295]]\n"
       ]
      }
     ],
     "prompt_number": 349
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "choice"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 350,
       "text": [
        "[0, 14, 8, 12, 6, 4]"
       ]
      }
     ],
     "prompt_number": 350
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}